{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import required libraries\nimport numpy as np\nimport tarfile\nimport os\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torchvision.datasets.utils import download_url\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torchvision.models import resnet18\n\ntorch.manual_seed(100)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:06:51.149120Z","iopub.execute_input":"2025-03-09T19:06:51.149395Z","iopub.status.idle":"2025-03-09T19:06:56.739435Z","shell.execute_reply.started":"2025-03-09T19:06:51.149368Z","shell.execute_reply":"2025-03-09T19:06:56.738579Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7d6d71ccb0f0>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"**Helper Functions**","metadata":{}},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\ndef training_step(model, batch):\n    images, labels = batch\n    images, labels = images.to(device), labels.to(device)\n    out = model(images)                  \n    loss = F.cross_entropy(out, labels) \n    return loss\n\ndef validation_step(model, batch):\n    images, labels = batch\n    images, labels = images.to(device), labels.to(device)\n    out = model(images)                    \n    loss = F.cross_entropy(out, labels)   \n    acc = accuracy(out, labels)\n    return {'Loss': loss.detach(), 'Acc': acc}\n\ndef validation_epoch_end(model, outputs):\n    batch_losses = [x['Loss'] for x in outputs]\n    epoch_loss = torch.stack(batch_losses).mean()   \n    batch_accs = [x['Acc'] for x in outputs]\n    epoch_acc = torch.stack(batch_accs).mean()      \n    return {'Loss': epoch_loss.item(), 'Acc': epoch_acc.item()}\n\ndef epoch_end(model, epoch, result):\n    print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n        epoch, result['lrs'][-1], result['train_loss'], result['Loss'], result['Acc']))\n    \ndef distance(model,model0):\n    distance=0\n    normalization=0\n    for (k, p), (k0, p0) in zip(model.named_parameters(), model0.named_parameters()):\n        space='  ' if 'bias' in k else ''\n        current_dist=(p.data0-p0.data0).pow(2).sum().item()\n        current_norm=p.data0.pow(2).sum().item()\n        distance+=current_dist\n        normalization+=current_norm\n    print(f'Distance: {np.sqrt(distance)}')\n    print(f'Normalized Distance: {1.0*np.sqrt(distance/normalization)}')\n    return 1.0*np.sqrt(distance/normalization)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:06:56.740261Z","iopub.execute_input":"2025-03-09T19:06:56.740677Z","iopub.status.idle":"2025-03-09T19:06:56.748950Z","shell.execute_reply.started":"2025-03-09T19:06:56.740653Z","shell.execute_reply":"2025-03-09T19:06:56.748089Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [validation_step(model, batch) for batch in val_loader]\n    return validation_epoch_end(model, outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n\n    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n    \n    for epoch in range(epochs): \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in train_loader:\n            loss = training_step(model, batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            lrs.append(get_lr(optimizer))\n            \n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        epoch_end(model, epoch, result)\n        history.append(result)\n        sched.step(result['Loss'])\n    return history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:06:57.404306Z","iopub.execute_input":"2025-03-09T19:06:57.404622Z","iopub.status.idle":"2025-03-09T19:06:57.411644Z","shell.execute_reply.started":"2025-03-09T19:06:57.404593Z","shell.execute_reply":"2025-03-09T19:06:57.410787Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"****Train/Load the Model****","metadata":{}},{"cell_type":"code","source":"# Dowload the dataset\ndataset_url = \"https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz\"\ndownload_url(dataset_url, '.')\n\n# Extract from archive\nwith tarfile.open('./cifar10.tgz', 'r:gz') as tar:\n    tar.extractall(path='./data')\n    \n# Look into the data directory\ndata_dir = './data/cifar10'\nprint(os.listdir(data_dir))\nclasses = os.listdir(data_dir + \"/train\")\nprint(classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:07:05.884447Z","iopub.execute_input":"2025-03-09T19:07:05.884868Z","iopub.status.idle":"2025-03-09T19:07:20.759558Z","shell.execute_reply.started":"2025-03-09T19:07:05.884830Z","shell.execute_reply":"2025-03-09T19:07:20.758836Z"}},"outputs":[{"name":"stdout","text":"Downloading https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz to ./cifar10.tgz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 135M/135M [00:02<00:00, 46.3MB/s] \n","output_type":"stream"},{"name":"stdout","text":"['test', 'train']\n['automobile', 'ship', 'airplane', 'deer', 'truck', 'horse', 'dog', 'bird', 'cat', 'frog']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"transform_train = tt.Compose([\n    tt.ToTensor(),\n    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = tt.Compose([\n    tt.ToTensor(),\n    tt.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:07:20.760524Z","iopub.execute_input":"2025-03-09T19:07:20.760821Z","iopub.status.idle":"2025-03-09T19:07:20.764975Z","shell.execute_reply.started":"2025-03-09T19:07:20.760789Z","shell.execute_reply":"2025-03-09T19:07:20.764109Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_ds = ImageFolder(data_dir+'/train', transform_train)\nvalid_ds = ImageFolder(data_dir+'/test', transform_test)\nbatch_size = 256\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True)\nvalid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:07:30.240460Z","iopub.execute_input":"2025-03-09T19:07:30.240827Z","iopub.status.idle":"2025-03-09T19:07:30.394700Z","shell.execute_reply.started":"2025-03-09T19:07:30.240784Z","shell.execute_reply":"2025-03-09T19:07:30.393847Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = \"cuda:0\"\nmodel = resnet18(num_classes = 10).to(device = device)\n\nepochs = 40\nmax_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:07:43.056368Z","iopub.execute_input":"2025-03-09T19:07:43.056705Z","iopub.status.idle":"2025-03-09T19:07:43.521054Z","shell.execute_reply.started":"2025-03-09T19:07:43.056675Z","shell.execute_reply":"2025-03-09T19:07:43.520123Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"%%time\nhistory = fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, \n                             grad_clip=grad_clip, \n                             weight_decay=weight_decay, \n                             opt_func=opt_func)\n\ntorch.save(model.state_dict(), \"ResNET18_CIFAR10_ALL_CLASSES.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:07:50.070075Z","iopub.execute_input":"2025-03-09T19:07:50.070393Z","iopub.status.idle":"2025-03-09T19:16:15.330844Z","shell.execute_reply.started":"2025-03-09T19:07:50.070366Z","shell.execute_reply":"2025-03-09T19:16:15.329808Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch [0], last_lr: 0.01000, train_loss: 1.8713, val_loss: 1.5713, val_acc: 0.4221\nEpoch [1], last_lr: 0.01000, train_loss: 1.3667, val_loss: 1.2546, val_acc: 0.5493\nEpoch [2], last_lr: 0.01000, train_loss: 1.1140, val_loss: 1.4517, val_acc: 0.5524\nEpoch [3], last_lr: 0.01000, train_loss: 0.9838, val_loss: 1.1750, val_acc: 0.5867\nEpoch [4], last_lr: 0.01000, train_loss: 0.8694, val_loss: 0.9290, val_acc: 0.6722\nEpoch [5], last_lr: 0.01000, train_loss: 0.7950, val_loss: 0.9471, val_acc: 0.6741\nEpoch [6], last_lr: 0.01000, train_loss: 0.7466, val_loss: 0.9114, val_acc: 0.6911\nEpoch [7], last_lr: 0.01000, train_loss: 0.7085, val_loss: 0.8177, val_acc: 0.7174\nEpoch [8], last_lr: 0.01000, train_loss: 0.6704, val_loss: 0.8248, val_acc: 0.7200\nEpoch [9], last_lr: 0.01000, train_loss: 0.6436, val_loss: 0.8474, val_acc: 0.7120\nEpoch [10], last_lr: 0.01000, train_loss: 0.6163, val_loss: 0.8808, val_acc: 0.6994\nEpoch [11], last_lr: 0.01000, train_loss: 0.5916, val_loss: 0.8196, val_acc: 0.7239\nEpoch [12], last_lr: 0.00500, train_loss: 0.4390, val_loss: 0.7676, val_acc: 0.7510\nEpoch [13], last_lr: 0.00500, train_loss: 0.3906, val_loss: 0.7517, val_acc: 0.7595\nEpoch [14], last_lr: 0.00500, train_loss: 0.3583, val_loss: 0.8147, val_acc: 0.7448\nEpoch [15], last_lr: 0.00500, train_loss: 0.3306, val_loss: 0.8065, val_acc: 0.7538\nEpoch [16], last_lr: 0.00500, train_loss: 0.3106, val_loss: 0.8370, val_acc: 0.7555\nEpoch [17], last_lr: 0.00500, train_loss: 0.2859, val_loss: 0.9420, val_acc: 0.7290\nEpoch [18], last_lr: 0.00250, train_loss: 0.1512, val_loss: 0.9362, val_acc: 0.7675\nEpoch [19], last_lr: 0.00250, train_loss: 0.0907, val_loss: 1.0670, val_acc: 0.7634\nEpoch [20], last_lr: 0.00250, train_loss: 0.0975, val_loss: 1.0889, val_acc: 0.7589\nEpoch [21], last_lr: 0.00250, train_loss: 0.1050, val_loss: 1.1062, val_acc: 0.7526\nEpoch [22], last_lr: 0.00125, train_loss: 0.0458, val_loss: 1.1373, val_acc: 0.7665\nEpoch [23], last_lr: 0.00125, train_loss: 0.0158, val_loss: 1.1978, val_acc: 0.7679\nEpoch [24], last_lr: 0.00125, train_loss: 0.0073, val_loss: 1.2650, val_acc: 0.7661\nEpoch [25], last_lr: 0.00125, train_loss: 0.0045, val_loss: 1.2935, val_acc: 0.7660\nEpoch [26], last_lr: 0.00063, train_loss: 0.0027, val_loss: 1.3173, val_acc: 0.7671\nEpoch [27], last_lr: 0.00063, train_loss: 0.0022, val_loss: 1.3378, val_acc: 0.7672\nEpoch [28], last_lr: 0.00063, train_loss: 0.0018, val_loss: 1.3566, val_acc: 0.7683\nEpoch [29], last_lr: 0.00063, train_loss: 0.0018, val_loss: 1.3754, val_acc: 0.7646\nEpoch [30], last_lr: 0.00031, train_loss: 0.0015, val_loss: 1.3793, val_acc: 0.7652\nEpoch [31], last_lr: 0.00031, train_loss: 0.0016, val_loss: 1.4113, val_acc: 0.7651\nEpoch [32], last_lr: 0.00031, train_loss: 0.0013, val_loss: 1.4085, val_acc: 0.7655\nEpoch [33], last_lr: 0.00031, train_loss: 0.0012, val_loss: 1.4119, val_acc: 0.7647\nEpoch [34], last_lr: 0.00016, train_loss: 0.0011, val_loss: 1.4256, val_acc: 0.7656\nEpoch [35], last_lr: 0.00016, train_loss: 0.0011, val_loss: 1.4413, val_acc: 0.7657\nEpoch [36], last_lr: 0.00016, train_loss: 0.0012, val_loss: 1.4379, val_acc: 0.7653\nEpoch [37], last_lr: 0.00016, train_loss: 0.0010, val_loss: 1.4442, val_acc: 0.7647\nEpoch [38], last_lr: 0.00008, train_loss: 0.0009, val_loss: 1.4592, val_acc: 0.7642\nEpoch [39], last_lr: 0.00008, train_loss: 0.0009, val_loss: 1.4545, val_acc: 0.7659\nCPU times: user 4min 29s, sys: 22.8 s, total: 4min 51s\nWall time: 8min 25s\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Unlearning**","metadata":{}},{"cell_type":"code","source":"# defining the noise structure\nclass Noise(nn.Module):\n    def __init__(self, *dim):\n        super().__init__()\n        self.noise = torch.nn.Parameter(torch.randn(*dim), requires_grad = True)\n        \n    def forward(self):\n        return self.noise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:16:15.332501Z","iopub.execute_input":"2025-03-09T19:16:15.332831Z","iopub.status.idle":"2025-03-09T19:16:15.337366Z","shell.execute_reply.started":"2025-03-09T19:16:15.332793Z","shell.execute_reply":"2025-03-09T19:16:15.336421Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# List of all classes\nclasses = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# Classes and specific items to unlearn\nclasses_to_forget = [0, 2]  # Classes to unlearn\nitems_to_forget = {0: [10, 20, 30], 2: [15, 25, 35]}  # Specific items to unlearn from each class\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:20:14.187854Z","iopub.execute_input":"2025-03-09T19:20:14.188215Z","iopub.status.idle":"2025-03-09T19:20:14.192503Z","shell.execute_reply.started":"2025-03-09T19:20:14.188185Z","shell.execute_reply":"2025-03-09T19:20:14.191723Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Classwise list of samples\nnum_classes = 10\nclasswise_train = {}\nfor i in range(num_classes):\n    classwise_train[i] = []\n\nfor img, label in train_ds:\n    classwise_train[label].append((img, label))\n    \nclasswise_test = {}\nfor i in range(num_classes):\n    classwise_test[i] = []\n\nfor img, label in valid_ds:\n    classwise_test[label].append((img, label))\n\n# Getting specific samples to forget\nforget_samples = []\nfor cls in classes_to_forget:\n    for item_idx in items_to_forget[cls]:\n        forget_samples.append(classwise_train[cls][item_idx])\n\n# Getting some samples from retain classes\nnum_samples_per_class = 1000\nretain_samples = []\nfor i in range(len(classes)):\n    if classes[i] not in classes_to_forget:\n        retain_samples += classwise_train[i][:num_samples_per_class]\n        \n# Retain validation set\nretain_valid = []\nfor cls in range(num_classes):\n    if cls not in classes_to_forget:\n        for img, label in classwise_test[cls]:\n            retain_valid.append((img, label))\n            \n# Forget validation set\nforget_valid = []\nfor cls in range(num_classes):\n    if cls in classes_to_forget:\n        for img, label in classwise_test[cls]:\n            forget_valid.append((img, label))\n            \nforget_valid_dl = DataLoader(forget_valid, batch_size, num_workers=3, pin_memory=True)\nretain_valid_dl = DataLoader(retain_valid, batch_size*2, num_workers=3, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:20:53.553318Z","iopub.execute_input":"2025-03-09T19:20:53.553629Z","iopub.status.idle":"2025-03-09T19:21:18.467562Z","shell.execute_reply.started":"2025-03-09T19:20:53.553602Z","shell.execute_reply":"2025-03-09T19:21:18.466921Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"**Training the Noise**","metadata":{}},{"cell_type":"code","source":"# Training the Noise\n# Loading the model\nmodel = resnet18(num_classes = 10).to(device = device)\nmodel.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\n\n# Optimizing noise for specific items to forget\nnoises = {}\nfor cls in classes_to_forget:\n    print(\"Optimizing loss for class {}\".format(cls))\n    noises[cls] = Noise(batch_size, 3, 32, 32).cuda()\n    opt = torch.optim.Adam(noises[cls].parameters(), lr = 0.1)\n\n    num_epochs = 5\n    num_steps = 8\n    class_label = cls\n    for epoch in range(num_epochs):\n        total_loss = []\n        for batch in range(num_steps):\n            inputs = noises[cls]()\n            labels = torch.zeros(batch_size).cuda() + class_label\n            outputs = model(inputs)\n            loss = -F.cross_entropy(outputs, labels.long()) + 0.1 * torch.mean(torch.sum(torch.square(inputs), [1, 2, 3]))\n            opt.zero_grad()\n            loss.backward()\n            opt.step()\n            total_loss.append(loss.cpu().detach().numpy())\n        print(\"Loss: {}\".format(np.mean(total_loss)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:21:18.468725Z","iopub.execute_input":"2025-03-09T19:21:18.469046Z","iopub.status.idle":"2025-03-09T19:21:21.861494Z","shell.execute_reply.started":"2025-03-09T19:21:18.469013Z","shell.execute_reply":"2025-03-09T19:21:21.860696Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-21-a24304ad8c9e>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"ResNET18_CIFAR10_ALL_CLASSES.pt\"))\n","output_type":"stream"},{"name":"stdout","text":"Optimizing loss for class 0\nLoss: 191.98046875\nLoss: 41.55701446533203\nLoss: 0.4371225833892822\nLoss: -7.593050479888916\nLoss: -11.14496898651123\nOptimizing loss for class 2\nLoss: 192.28170776367188\nLoss: 41.19386672973633\nLoss: -0.002153754234313965\nLoss: -8.033639907836914\nLoss: -11.487071990966797\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"**Impair Step**","metadata":{}},{"cell_type":"code","source":"# Impair Step\nbatch_size = 256\nnoisy_data = []\nnum_batches = 20\n\nfor cls in classes_to_forget:\n    for i in range(num_batches):\n        batch = noises[cls]().cpu().detach()\n        for i in range(batch[0].size(0)):\n            noisy_data.append((batch[i], torch.tensor(cls)))\n\nother_samples = []\nfor i in range(len(retain_samples)):\n    other_samples.append((retain_samples[i][0].cpu(), torch.tensor(retain_samples[i][1])))\nnoisy_data += other_samples\nnoisy_loader = torch.utils.data.DataLoader(noisy_data, batch_size=256, shuffle=True)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.02)\n\nfor epoch in range(1):  \n    model.train(True)\n    running_loss = 0.0\n    running_acc = 0\n    for i, data in enumerate(noisy_loader):\n        inputs, labels = data\n        inputs, labels = inputs.cuda(), torch.tensor(labels).cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = F.cross_entropy(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # Print statistics\n        running_loss += loss.item() * inputs.size(0)\n        out = torch.argmax(outputs.detach(), dim=1)\n        assert out.shape == labels.shape\n        running_acc += (labels == out).sum().item()\n    print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)}, Train Acc: {running_acc*100/len(train_ds)}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:21:21.862953Z","iopub.execute_input":"2025-03-09T19:21:21.863221Z","iopub.status.idle":"2025-03-09T19:21:23.366670Z","shell.execute_reply.started":"2025-03-09T19:21:21.863185Z","shell.execute_reply":"2025-03-09T19:21:23.365799Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-22-83cc42cbf767>:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs, labels = inputs.cuda(), torch.tensor(labels).cuda()\n","output_type":"stream"},{"name":"stdout","text":"Train loss 1: 0.1682758599090576, Train Acc: 11.184%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# Performance after Impair Step\nprint(\"Performance of Standard Forget Model on Forget Class\")\nhistory = [evaluate(model, forget_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))\n\nprint(\"Performance of Standard Forget Model on Retain Class\")\nhistory = [evaluate(model, retain_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:21:23.367662Z","iopub.execute_input":"2025-03-09T19:21:23.367915Z","iopub.status.idle":"2025-03-09T19:21:24.172629Z","shell.execute_reply.started":"2025-03-09T19:21:23.367895Z","shell.execute_reply":"2025-03-09T19:21:24.171729Z"}},"outputs":[{"name":"stdout","text":"Performance of Standard Forget Model on Forget Class\nAccuracy: 1.708984375\nLoss: 6.45398473739624\nPerformance of Standard Forget Model on Retain Class\nAccuracy: 66.00097417831421\nLoss: 0.9493621587753296\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"**Repair Step**","metadata":{}},{"cell_type":"code","source":"# Repair Step\nheal_loader = torch.utils.data.DataLoader(other_samples, batch_size=256, shuffle=True)\n\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n\nfor epoch in range(1):  \n    model.train(True)\n    running_loss = 0.0\n    running_acc = 0\n    for i, data in enumerate(heal_loader):\n        inputs, labels = data\n        inputs, labels = inputs.cuda(), torch.tensor(labels).cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = F.cross_entropy(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # Print statistics\n        running_loss += loss.item() * inputs.size(0)\n        out = torch.argmax(outputs.detach(), dim=1)\n        assert out.shape == labels.shape\n        running_acc += (labels == out).sum().item()\n    print(f\"Train loss {epoch+1}: {running_loss/len(train_ds)}, Train Acc: {running_acc*100/len(train_ds)}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:21:24.173724Z","iopub.execute_input":"2025-03-09T19:21:24.174129Z","iopub.status.idle":"2025-03-09T19:21:25.562425Z","shell.execute_reply.started":"2025-03-09T19:21:24.174096Z","shell.execute_reply":"2025-03-09T19:21:25.561717Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-24-fa46ab7aa668>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  inputs, labels = inputs.cuda(), torch.tensor(labels).cuda()\n","output_type":"stream"},{"name":"stdout","text":"Train loss 1: 0.09966521217346191, Train Acc: 12.458%\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Performance after Repair Step\nprint(\"Performance of Standard Forget Model on Forget Class\")\nhistory = [evaluate(model, forget_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))\n\nprint(\"Performance of Standard Forget Model on Retain Class\")\nhistory = [evaluate(model, retain_valid_dl)]\nprint(\"Accuracy: {}\".format(history[0][\"Acc\"]*100))\nprint(\"Loss: {}\".format(history[0][\"Loss\"]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T19:21:25.563194Z","iopub.execute_input":"2025-03-09T19:21:25.563407Z","iopub.status.idle":"2025-03-09T19:21:26.343652Z","shell.execute_reply.started":"2025-03-09T19:21:25.563389Z","shell.execute_reply":"2025-03-09T19:21:26.342806Z"}},"outputs":[{"name":"stdout","text":"Performance of Standard Forget Model on Forget Class\nAccuracy: 0.0\nLoss: 10.666467666625977\nPerformance of Standard Forget Model on Retain Class\nAccuracy: 71.15722894668579\nLoss: 0.8484183549880981\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}